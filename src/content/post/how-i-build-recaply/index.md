---
title: "我是如何开发 Recaply 的"
publishDate: "28 Feb 2025"
description: "想到了一个新的创业的点子，就是做一个浏览器插件，分析用户的浏览历史，然后用AI来进行整理生成浏览日报"
tags: ["AI"]
---

这周在 v2ex 宣发完了 markflow，收集了一些用户反馈和意见，接下来就是慢慢优化，所以手上也没有很着急做的事情，昨晚饭后散步突然脑海中闪过一个点子，就是能不能再做一个浏览器扩展，用来分析用户的浏览记录，然后生成一篇markdown格式的博客，就像记日记一样，但是好处是不用自己动手花时间写。

问了一下 deepseek 和 gemini 都说这个点子很好，然后说市面上还没有类似的产品。给推荐了几个读取浏览记录的插件，都是简单的对浏览时长做统计分析的，不能生成日报。这样看来还真是被我找到了一个没被人关注过的领域，那么说干就干开始做吧。

## 产品命名

想名字依旧是一个很耗时间，很让人头疼的过程，不过还好我现在已经习惯让AI帮我做，我问了deepseek我想做一个基于用户浏览历史做日报的插件，用什么名字来命名这个产品好，deepseek给我推荐了以下几个：

1. dailypulse
2. recaply
3. browseai

我比较了一下发现还是 recaply 比较好听，回顾的意思，跟我这个日报也比较接近。

接下来就是去 godaddy 注册域名，依旧选择注册便宜的域名，挑了几个不好做决定，也是让 deepseek 帮我选，我给了如下选项

1. recaply.xyz
2. recaply.cc
3. recaply.info

不出所料deepseek给我推荐了 recaply.xyz 说 .xyz 域名比较有科技感，也比较新，那么就没啥好纠结的了，花15块钱注册了这个域名，然后转移到 cloudflare 上，前期工作做完，接下来就可以开始写代码了。

## logo 设计

本来设计产品logo也是个比较耗时的过程，但是我对自己要求比较低，我只想快速完成 MVP 的开发，所以在设计logo这块我还是基于开源的svg logo让AI帮我修改。

先去 iconoir.com 上面看一些比较满意的logo，我选择了 `report` 这个，因为我的产品就是生成日报，用这个logo挺直观的。

虽然是开源的logo但也不能直接照抄，我让 github copilot 基于这个logo改了一下，加上一些 AI 的元素，就得到了下面这个图

<svg width="24px" height="24px" stroke-width="1.5" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
    <defs>
        <linearGradient id="aiGradient" x1="0%" y1="0%" x2="100%" y2="100%">
            <stop offset="0%" stop-color="#4285F4" />
            <stop offset="100%" stop-color="#7B1FA2" />
        </linearGradient>
    </defs>
    <path
        d="M9 21H15M9 21V16M9 21H3.6C3.26863 21 3 20.7314 3 20.4V16.6C3 16.2686 3.26863 16 3.6 16H9M15 21V9M15 21H20.4C20.7314 21 21 20.7314 21 20.4V3.6C21 3.26863 20.7314 3 20.4 3H15.6C15.2686 3 15 3.26863 15 3.6V9M15 9H9.6C9.26863 9 9 9.26863 9 9.6V16"
        stroke="url(#aiGradient)" stroke-width="1.5"></path>
</svg>

有了个蓝紫色的渐变色，比默认的黑色线条好多了，看起来不错，暂时就用这个吧。

## 产品开发

传统的开发流程应该是先在草稿纸上画线稿，然后去 figma 上画设计稿，然后再切成前端页面，再开发后端。但是作为一个个人项目，没时间也没这么多精力按这个步骤去做，所以我还是使用 AI 辅助的方式，代码优先，边做边改。

### 第一版插件主界面

我首先想到的是做一个popup弹窗，里面放用户生成了的日报列表，然后可以点击底部按钮跳转到官网去查看更多，我的提示词是这样的：

```markdown
使用 tailwindcss + daisyui 帮我设计一下这个插件的 popup 的 UI，我希望popup内包含：

一个url列表，用来展示AI帮用户生成的日报列表
底部一个查看更多按钮，打开网页跳转到用户的主页
```

很快 AI 给我生成了UI代码，效果图如下：

![recaply ui 1](recaply-ui-1.png)

看起来效果不错，但是有个问题，这个界面没有生成日报的按钮，如果按这个流程来的话，只能是在后台默默地去调用接口生成日报，然后用户只需要打开扩展看日报就行，交互流程虽然很简单，但是对用户隐私权侵犯可能太严重了，不声不响就在后台上传用户浏览记录。虽然这些互联网大厂都在不遗余力的监控用户行为，但是我作为一个第三方，还是尊重一下用户隐私好了，该加一个按钮触发提交浏览历史的操作，让用户看到服务器要哪些数据，然后主动提交，绝对不在后台自动提交。

### 第二版插件主界面

上面说到尊重用户隐私，所以我想主界面应该是一个表单，列出了用户昨天的浏览记录，然后询问是否要提交到服务器去生成浏览日报。

我是这么对 github copilot 下命令的：

```markdown
帮我重新设计一下这个 popup 的首页，我希望列表页里展示的是用户昨天的浏览历史统计，然后底部一个按钮询问用户是否生成浏览日报
```

很快就生成了代码，测试后效果图如下：

![recaply ui 2](recaply-ui-2.png)

效果不错，按这个UI去组织浏览记录的数据就好了。接下来得思考下如何保存浏览记录的详情，因为 `chrome.history` 这个api只能拿到标题和url，如果我要生成详细日报肯定还需要分析用户看到的网页内容，比如说在什么值得买点了很多个网页，说明这段时间对电子产品或者购物很感兴趣，应该要把这些详情也记录下来，而不仅仅是写一句你访问了5个什么值得买的页面，说明你这段时间想买东西。只是分析个标题的话根本不叫 AI日报，过一个月再回来看，也许什么都回忆不起来，还是得再日报里加上网页总结图文，这样几年后回来再看到这份日报就会恍然大悟，啊，原来那几天我对xx产品这么关注这么想买啊，现在都跌成啥样了，还好没买。

### 思考如何生成日报

网上一堆人发视频说AI对他们帮助多大，用AI生成的周报被老板表扬啥的，我没用 AI 写过日报周报，在我印象中，deepseek 生成的内容都比较短，在我这个场景中如果用户一天看了100个网页，生成的日报怎么也得5000字以上吧，不如就太简单了，所以得想一下怎么才能让 AI 生成美观好看又详细的日报。

还是先启发一下 AI，给我明确一下思路：

![ask ai how to generate a report](ask-ai-generate-report.png)

一下就帮我把服务器接口和提示词模板都生成了，看起来不错，但是似乎少了 content 字段，再问一下AI是不是应该把网站内容也给提交过去，AI 也很赞同，并且更新了一下接口字段，加上了 content，这个 content 是网站的主要内容。

```json
{
  "date": "2023-10-15",
  "browsing_data": [
    {
      "url": "https://example.com/news",
      "title": "Breaking News: Major Event",
      "time_spent": "5 minutes",
      "category": "新闻",
      "content": "今日发生了一起重大事件，涉及全球经济波动。专家表示，这一事件可能会对金融市场产生长期影响……"
    },
    {
      "url": "https://example.com/work",
      "title": "Project Management Tips",
      "time_spent": "15 minutes",
      "category": "工作",
      "content": "本文分享了5个提升项目管理效率的技巧：1. 明确目标；2. 合理分配资源；3. 定期沟通……"
    },
    {
      "url": "https://example.com/entertainment",
      "title": "Top 10 Movies of 2023",
      "time_spent": "20 minutes",
      "category": "娱乐",
      "content": "2023年最受欢迎的10部电影包括《电影A》、《电影B》和《电影C》。这些电影在票房和口碑上均表现出色……"
    }
  ]
}
```

### 设计抓取的内容

根据上面AI给我设计的接口字段，我需要在前端组装好 `browseing_data` 提交给服务器，这里面 `url`, `title`, `time_spent` 应该都能通过 `chrome.history` 这个 api 获取到，`category` 应该是我们自己对已知的网站域名做一些分类，`content` 就要自己提取了。

之前做 MypodSpace 和 Markflow 我都需要读取当前网页内容，当时是通过 `@mozilla/readability` 这个库来读的，这个库能智能识别和提取主体内容，但是效果比较粗糙，对于一些未知的网站用这个库来提取内容可以，但是对于一些主流网站，最好是手写一些抓取的代码，这样提取的内容比较准确，脏数据更少。
